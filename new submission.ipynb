{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0517478c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-30T16:04:17.136239Z",
     "iopub.status.busy": "2022-10-30T16:04:17.135752Z",
     "iopub.status.idle": "2022-10-30T16:04:17.149773Z",
     "shell.execute_reply": "2022-10-30T16:04:17.148839Z"
    },
    "papermill": {
     "duration": 0.0243,
     "end_time": "2022-10-30T16:04:17.152377",
     "exception": false,
     "start_time": "2022-10-30T16:04:17.128077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af2548e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:04:17.165345Z",
     "iopub.status.busy": "2022-10-30T16:04:17.164892Z",
     "iopub.status.idle": "2022-10-30T16:04:51.060352Z",
     "shell.execute_reply": "2022-10-30T16:04:51.058685Z"
    },
    "papermill": {
     "duration": 33.90591,
     "end_time": "2022-10-30T16:04:51.063530",
     "exception": false,
     "start_time": "2022-10-30T16:04:17.157620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow[full] in /opt/conda/lib/python3.7/site-packages (2.6.4)\r\n",
      "\u001b[33mWARNING: tensorflow 2.6.4 does not provide the extra 'full'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (1.12.1)\r\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (0.2.0)\r\n",
      "Collecting tensorboard<2.7,>=2.6.0\r\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (1.43.0)\r\n",
      "Collecting numpy~=1.19.2\r\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (1.6.3)\r\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (0.37.1)\r\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (3.19.4)\r\n",
      "Requirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (5.0)\r\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (0.15.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (2.6.0)\r\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (1.12)\r\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (1.15.0)\r\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (0.4.0)\r\n",
      "Collecting h5py~=3.1.0\r\n",
      "  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting typing-extensions<3.11,>=3.7\r\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\r\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (2.6.0)\r\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (1.1.2)\r\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (1.1.0)\r\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow[full]) (3.3.0)\r\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow[full]) (1.5.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow[full]) (3.3.7)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow[full]) (59.8.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow[full]) (2.28.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow[full]) (1.8.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow[full]) (1.35.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow[full]) (0.4.6)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow[full]) (2.2.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow[full]) (0.6.1)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow[full]) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow[full]) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow[full]) (4.8)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow[full]) (1.3.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow[full]) (4.13.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow[full]) (2022.9.24)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow[full]) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow[full]) (1.26.12)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow[full]) (2.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow[full]) (2.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow[full]) (3.8.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow[full]) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow[full]) (3.2.0)\r\n",
      "Installing collected packages: typing-extensions, numpy, h5py, tensorboard\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.4.0\r\n",
      "    Uninstalling typing_extensions-4.4.0:\r\n",
      "      Successfully uninstalled typing_extensions-4.4.0\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.21.6\r\n",
      "    Uninstalling numpy-1.21.6:\r\n",
      "      Successfully uninstalled numpy-1.21.6\r\n",
      "  Attempting uninstall: h5py\r\n",
      "    Found existing installation: h5py 3.7.0\r\n",
      "    Uninstalling h5py-3.7.0:\r\n",
      "      Successfully uninstalled h5py-3.7.0\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.10.1\r\n",
      "    Uninstalling tensorboard-2.10.1:\r\n",
      "      Successfully uninstalled tensorboard-2.10.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\r\n",
      "tfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\r\n",
      "tfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "tensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "pytorch-lightning 1.7.7 requires tensorboard>=2.9.1, but you have tensorboard 2.6.0 which is incompatible.\r\n",
      "pytorch-lightning 1.7.7 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\r\n",
      "pandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\r\n",
      "nnabla 1.31.0 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\r\n",
      "jaxlib 0.3.22 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\r\n",
      "jax 0.3.23 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\r\n",
      "flax 0.6.1 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "flake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.13.0 which is incompatible.\r\n",
      "featuretools 1.11.1 requires numpy>=1.21.0, but you have numpy 1.19.5 which is incompatible.\r\n",
      "cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\r\n",
      "apache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\r\n",
      "apache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 8.0.0 which is incompatible.\r\n",
      "allennlp 2.10.0 requires h5py>=3.6.0, but you have h5py 3.1.0 which is incompatible.\r\n",
      "allennlp 2.10.0 requires numpy>=1.21.4, but you have numpy 1.19.5 which is incompatible.\r\n",
      "allennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\r\n",
      "aioitertools 0.11.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "aiobotocore 2.4.0 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.27.93 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed h5py-3.1.0 numpy-1.19.5 tensorboard-2.6.0 typing-extensions-3.10.0.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc5f243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:04:51.079036Z",
     "iopub.status.busy": "2022-10-30T16:04:51.078668Z",
     "iopub.status.idle": "2022-10-30T16:05:00.149183Z",
     "shell.execute_reply": "2022-10-30T16:05:00.147466Z"
    },
    "papermill": {
     "duration": 9.081243,
     "end_time": "2022-10-30T16:05:00.151955",
     "exception": false,
     "start_time": "2022-10-30T16:04:51.070712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /opt/conda/lib/python3.7/site-packages (0.14.0)\r\n",
      "Requirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow_addons) (2.13.3)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8f2618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:00.171487Z",
     "iopub.status.busy": "2022-10-30T16:05:00.171054Z",
     "iopub.status.idle": "2022-10-30T16:05:07.359945Z",
     "shell.execute_reply": "2022-10-30T16:05:07.357614Z"
    },
    "papermill": {
     "duration": 7.203658,
     "end_time": "2022-10-30T16:05:07.362920",
     "exception": false,
     "start_time": "2022-10-30T16:05:00.159262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2226ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:07.380939Z",
     "iopub.status.busy": "2022-10-30T16:05:07.379185Z",
     "iopub.status.idle": "2022-10-30T16:05:07.386362Z",
     "shell.execute_reply": "2022-10-30T16:05:07.385118Z"
    },
    "papermill": {
     "duration": 0.01875,
     "end_time": "2022-10-30T16:05:07.389449",
     "exception": false,
     "start_time": "2022-10-30T16:05:07.370699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a14538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:07.408427Z",
     "iopub.status.busy": "2022-10-30T16:05:07.408000Z",
     "iopub.status.idle": "2022-10-30T16:05:07.858893Z",
     "shell.execute_reply": "2022-10-30T16:05:07.857413Z"
    },
    "papermill": {
     "duration": 0.464445,
     "end_time": "2022-10-30T16:05:07.861346",
     "exception": false,
     "start_time": "2022-10-30T16:05:07.396901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c348b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:07.877285Z",
     "iopub.status.busy": "2022-10-30T16:05:07.876894Z",
     "iopub.status.idle": "2022-10-30T16:05:07.895928Z",
     "shell.execute_reply": "2022-10-30T16:05:07.894633Z"
    },
    "papermill": {
     "duration": 0.029882,
     "end_time": "2022-10-30T16:05:07.898398",
     "exception": false,
     "start_time": "2022-10-30T16:05:07.868516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_full = np.concatenate((X_train_raw, X_test_raw))\n",
    "y_train_full = np.concatenate((y_train_raw, y_test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef5d6122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:07.914788Z",
     "iopub.status.busy": "2022-10-30T16:05:07.914419Z",
     "iopub.status.idle": "2022-10-30T16:05:12.644376Z",
     "shell.execute_reply": "2022-10-30T16:05:12.643110Z"
    },
    "papermill": {
     "duration": 4.741059,
     "end_time": "2022-10-30T16:05:12.647014",
     "exception": false,
     "start_time": "2022-10-30T16:05:07.905955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid = pd.read_csv('../input/digit-recognizer/train.csv').to_numpy()\n",
    "test = pd.read_csv('../input/digit-recognizer/test.csv').to_numpy()\n",
    "sample_submission = pd.read_csv('../input/digit-recognizer/sample_submission.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "951be0e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:12.665345Z",
     "iopub.status.busy": "2022-10-30T16:05:12.664966Z",
     "iopub.status.idle": "2022-10-30T16:05:12.894466Z",
     "shell.execute_reply": "2022-10-30T16:05:12.893605Z"
    },
    "papermill": {
     "duration": 0.241276,
     "end_time": "2022-10-30T16:05:12.896344",
     "exception": false,
     "start_time": "2022-10-30T16:05:12.655068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 28, 28, 1) (42000, 28, 28, 1) (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_Y = keras.utils.to_categorical(y_train_full)\n",
    "valid_Y = keras.utils.to_categorical(valid[:,0])\n",
    "\n",
    "# Preprocess Normalisation :\n",
    "train_X = X_train_full / 255.0\n",
    "valid_X = valid[:,1:] / 255.0\n",
    "test_X = test / 255.0\n",
    "\n",
    "# Preprocess for tensor inputs :\n",
    "train_X = train_X.reshape(-1, 28, 28, 1)\n",
    "valid_X = valid_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Verification of shapes :\n",
    "print(train_X.shape,valid_X.shape,test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1162be95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:12.912289Z",
     "iopub.status.busy": "2022-10-30T16:05:12.911923Z",
     "iopub.status.idle": "2022-10-30T16:05:12.916418Z",
     "shell.execute_reply": "2022-10-30T16:05:12.915545Z"
    },
    "papermill": {
     "duration": 0.01524,
     "end_time": "2022-10-30T16:05:12.918917",
     "exception": false,
     "start_time": "2022-10-30T16:05:12.903677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 25\n",
    "steps = len(train_X) // batch_size\n",
    "labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca75304",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:12.935691Z",
     "iopub.status.busy": "2022-10-30T16:05:12.935169Z",
     "iopub.status.idle": "2022-10-30T16:05:13.487856Z",
     "shell.execute_reply": "2022-10-30T16:05:13.486753Z"
    },
    "papermill": {
     "duration": 0.563849,
     "end_time": "2022-10-30T16:05:13.490485",
     "exception": false,
     "start_time": "2022-10-30T16:05:12.926636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 16:05:12.956196: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "train_DS = tf.data.Dataset.from_tensor_slices((train_X, train_Y))\n",
    "valid_DS = tf.data.Dataset.from_tensor_slices((valid_X, valid_Y))\n",
    "\n",
    "train_DS = train_DS.shuffle(steps * batch_size).batch(batch_size).repeat().prefetch(tf.data.AUTOTUNE)\n",
    "valid_DS = valid_DS.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba88ba1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:13.508260Z",
     "iopub.status.busy": "2022-10-30T16:05:13.507822Z",
     "iopub.status.idle": "2022-10-30T16:05:13.518541Z",
     "shell.execute_reply": "2022-10-30T16:05:13.517326Z"
    },
    "papermill": {
     "duration": 0.022678,
     "end_time": "2022-10-30T16:05:13.521429",
     "exception": false,
     "start_time": "2022-10-30T16:05:13.498751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "class Model:\n",
    "    \n",
    "    @staticmethod\n",
    "    \n",
    "    def build(height, width, depth):\n",
    "        model = keras.Sequential()\n",
    "        \n",
    "        # Input\n",
    "        model.add(Input((height, width, depth)))\n",
    "        \n",
    "        # CNN LAYERS\n",
    "        model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "        model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "        model.add(MaxPooling2D(2, 2))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "        model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "        model.add(MaxPooling2D(2, 2))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "        model.add(MaxPooling2D(2, 2))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(128, activation = 'relu'))\n",
    "        model.add(Dense(128, activation = 'relu'))\n",
    "        model.add(Dense(10, activation = 'softmax'))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1849e701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:13.540042Z",
     "iopub.status.busy": "2022-10-30T16:05:13.538368Z",
     "iopub.status.idle": "2022-10-30T16:05:13.940629Z",
     "shell.execute_reply": "2022-10-30T16:05:13.939708Z"
    },
    "papermill": {
     "duration": 0.413524,
     "end_time": "2022-10-30T16:05:13.942996",
     "exception": false,
     "start_time": "2022-10-30T16:05:13.529472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 174,058\n",
      "Trainable params: 173,610\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model.build(28,28,1)\n",
    "model.summary()\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate = 5e-4)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience = 5,\n",
    "                                              min_delta = 1e-3,\n",
    "                                              restore_best_weights = True)\n",
    "\n",
    "chkpt = keras.callbacks.ModelCheckpoint(filepath = 'best_model_todate', save_best_only = True, save_weights_only = True)\n",
    "\n",
    "endNan = keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 20:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "LRS = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "LRP = keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 5, verbose = 3)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'SGD',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    steps_per_execution = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec001c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:13.961916Z",
     "iopub.status.busy": "2022-10-30T16:05:13.960486Z",
     "iopub.status.idle": "2022-10-30T16:05:14.186341Z",
     "shell.execute_reply": "2022-10-30T16:05:14.184227Z"
    },
    "papermill": {
     "duration": 0.238414,
     "end_time": "2022-10-30T16:05:14.189519",
     "exception": false,
     "start_time": "2022-10-30T16:05:13.951105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EPOCHS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EPOCHS' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 40 # Model was trained on 20 epoch before the last 5 who are here\n",
    "\n",
    "Mdl1 = model.fit(train_DS,\n",
    "                validation_data = valid_DS,\n",
    "                epochs = EPOCHS,\n",
    "                steps_per_epoch = steps,\n",
    "                callbacks = [early_stopping, LRS, chkpt, LRP, endNan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01562401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:05:14.207602Z",
     "iopub.status.busy": "2022-10-30T16:05:14.207210Z",
     "iopub.status.idle": "2022-10-30T16:05:14.240369Z",
     "shell.execute_reply": "2022-10-30T16:05:14.238469Z"
    },
    "papermill": {
     "duration": 0.045235,
     "end_time": "2022-10-30T16:05:14.243100",
     "exception": true,
     "start_time": "2022-10-30T16:05:14.197865",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mdl1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20/488919199.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMdl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Mdl1' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(Mdl1.history)\n",
    "df.index +=1\n",
    "\n",
    "fig = plt.figure(figsize = (20, 5))\n",
    "fig.suptitle('Validation metrics')\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax1.set_xticks(range(len(df)+1))\n",
    "ax2.set_xticks(range(len(df)+1))\n",
    "\n",
    "df[['loss', 'val_loss']].plot(title = \"Cross Entropy\", grid = True, ax = ax1)\n",
    "df[['accuracy', 'val_accuracy']].plot(title = \"Accuracy\", grid = True, ax = ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9626cb91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:02:44.353203Z",
     "iopub.status.busy": "2022-10-30T16:02:44.352832Z",
     "iopub.status.idle": "2022-10-30T16:02:44.386330Z",
     "shell.execute_reply": "2022-10-30T16:02:44.385410Z",
     "shell.execute_reply.started": "2022-10-30T16:02:44.353175Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('model.h5', save_format = 'h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b5f80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:03:08.312186Z",
     "iopub.status.busy": "2022-10-30T16:03:08.311795Z",
     "iopub.status.idle": "2022-10-30T16:03:15.647211Z",
     "shell.execute_reply": "2022-10-30T16:03:15.646350Z",
     "shell.execute_reply.started": "2022-10-30T16:03:08.312155Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_X)\n",
    "classes = pred.argmax(axis=-1)\n",
    "\n",
    "\n",
    "sub = pd.read_csv('../input/digit-recognizer/sample_submission.csv')\n",
    "sub.Label = classes\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69b643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T16:03:32.002450Z",
     "iopub.status.busy": "2022-10-30T16:03:32.002099Z",
     "iopub.status.idle": "2022-10-30T16:03:32.033573Z",
     "shell.execute_reply": "2022-10-30T16:03:32.032820Z",
     "shell.execute_reply.started": "2022-10-30T16:03:32.002423Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b5a2b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 68.139079,
   "end_time": "2022-10-30T16:05:16.994381",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-30T16:04:08.855302",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
